<!doctype html><html lang=en-us><head><meta name=generator content="Hugo 0.145.0"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Home | A minimal Hugo website</title>
<link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><script src=https://kit.fontawesome.com/cdd93c4598.js crossorigin=anonymous></script></head><body><nav><ul class=menu><li><a href=/>Home</a></li><li><a href=/papers/>Papers</a></li><li><a href=/talks/>Talks</a></li><li><a href=/courses/>Courses</a></li><li><a href=/contact/>Contact</a></li><li><a href=/blog/>Blog</a></li><li><a href=https://chicagohai.github.io/>Lab</a></li></ul><hr></nav><img src=images/web_circle_small.jpg style=max-width:30%;min-width:40px;float:right alt="Github repo"><h1 id=chenhao-tan-谭宸浩>Chenhao Tan (谭宸浩)</h1><p>I am an associate professor at the <a href=https://cs.uchicago.edu/>Department of Computer Science</a> and <a href=https://datascience.uchicago.edu/>Data Science</a> at the <a href=https://www.uchicago.edu/>University of Chicago</a>.
I direct the <a href=https://chicagohai.github.io/>Chicago Human+AI lab</a> (CHAI) (<a href=https://bsky.app/profile/chicagohai.bsky.social><i class="fa-brands fa-bluesky" style=color:#74c0fc></i></a>).
I am also a visiting scientist at <a href=https://www.abridge.com/>Abridge</a>.
You can learn more about my life trajectory and find my official biography <a href=/bio>here</a>.</p><p>My research brings together social sciences and machine learning to develop the best AI for humans. The applications that I am most interested in are 1) scientific discoveries, 2) healthcare, and 3) governance and democratic processes (ordered by random coin flips).</p><p>The central question of my current interest lies in how we can build an effective communication protocol between humans and AI. Here are some example problems that I think will contribute to this question:</p><ul><li><strong>Specification</strong>: How can we help AI understand human goals and help humans specify their goals? Prompting and reinforcement learning from human feedback are the main paradigms right now, but what about goals that cannot be easily described or elicited through human preferences? Examples include <a href=https://chicagohai.github.io/hypogenic-demo/>data-driven hypothesis generation</a> and <a href=https://arxiv.org/abs/2109.06896>decision-focused summarization</a>.</li><li><strong>Complementary AI</strong>: How can we develop AI that accounts for human intuitions/biases and complement human intelligence/enable humans to supervise powerful AI that outperforms humans (&ldquo;scalable oversight&rdquo;)? This requires us to model human intuitions/biases and address them constructively. We have done some prior work on the important role of human similarity judgments in <a href=https://arxiv.org/abs/2303.04809>case-based explanations</a> and generally <a href=https://arxiv.org/abs/2202.04092>machine explanations</a>. But we will need fundamental breakthroughs in behavioral sciences, which in turn inform AI modeling/inference.</li><li><strong>Interpretability</strong>: How can we make sense of (powerful) AI that is much better than humans? I am most interested in interpretability for expanding human knowledge (e.g., in scientific discoveries) and for improving the controllability of AI. It is important to explore opportunities in the absence of identifiability.</li></ul><p>In general, goals matter more to me than the specific problem or method. For instance, while hallucination is not among the above problems, I spend a lot of time thinking about hallucination at Abridge, as non-factual statements are very problematic for generating clinical notes in healthcare.</p><p>If you are interested in seeing how my research description has evolved, you can check this <a href=/bio>page</a>.</p><h2 id=selected-recent-work>Selected recent work</h2><ul><li><a href=https://laoliu5280.github.io/>Haokun Liu*</a>, <a href=https://rosafish.github.io>Yangqiaoyu Zhou*</a>, Mingxuan Li*, Chenfei Yuan, and <em>Chenhao Tan</em>. <a href=https://arxiv.org/abs/2410.17309>Literature Meets Data: A Synergistic Approach to Hypothesis Generation</a>. <a href=https://chicagohai.github.io/hypogenic-demo/>[Website]</a></li><li><a href=https://rosafish.github.io>Yangqiaoyu Zhou</a>, <a href=https://laoliu5280.github.io/>Haokun Liu</a>, Tejes Srivastava, <a href=https://www.hongyuanmei.com/>Hongyuan Mei</a>, and <em>Chenhao Tan</em>. <a href=https://arxiv.org/abs/2404.04326>Hypothesis Generation with Large Language Models</a>. NLP4Science workshop at EMNLP 2024.</li><li><a href=https://chacha-chen.github.io>Chacha Chen</a>, <a href=http://www.shifeng.umiacs.io>Shi Feng</a>, <a href=http://www.amitsharma.in/>Amit Sharma</a>, and <em>Chenhao Tan</em>. <a href=https://arxiv.org/abs/2202.04092>Machine Explanations and Human Understanding</a>. Accepted at Transactions on Machine Learning Research (TMLR); presented at FAccT 2023; <strong>Best paper award</strong> at the ICML 2022 Workshop on Human-Machine Collaboration and Teaming (<a href="https://drive.google.com/file/d/1Wi7toZjzIIDG3jAULnrb3UXTu49aJCeq/view?usp=sharing">workshop version</a>).</li><li><a href=https://mrsata.github.io/>Han Liu</a>, <a href=https://harry-tian.github.io>Yizhou Tian</a>, <a href=https://chacha-chen.github.io>Chacha Chen</a>, <a href=http://www.shifeng.umiacs.io>Shi Feng</a>, <a href=https://yuxinchen.org>Yuxin Chen</a>, and <em>Chenhao Tan</em>. <a href=https://arxiv.org/abs/2303.04809>Learning Human-Compatible Representations for Case-Based Decision Support</a>. In Proceedings of ICLR 2023.</li></ul><h2 id=openings>Openings</h2><p>As of fall 2024, you can apply to work with me through</p><ul><li>the UChicago <a href=https://cs.uchicago.edu/academics/admission/?phd>Computer Science PhD program</a>,</li><li>the UChicago <a href=https://codas.uchicago.edu/how-to-apply/>Data Science PhD program</a> (the first ever cohort!),</li><li>the <a href=https://datascience.uchicago.edu/research/postdoctoral-programs/dsi-scholars/#description>Data Science Instituite Postdoctoral program</a> (<strong>If you applied to the DSI postdoc program and mentioned me as an advisor, please send me an email because I can potentially support you with my own funding</strong>).</li></ul><p><strong>I also have a postdoc opening on human-centered AI that can start any time.</strong> Please email <a href=/contact>me</a> your CV and names of references. I am particularly open to students who have background in medicine and policy (e.g., MD/PhD and PhD students in economics).
I am always looking for motivated masters and undergraduate students who are interested in human-centered AI, NLP, and computational social science.
Please read this <a href=/faq>FAQ</a> before contacting me.</p><h2 id=demos--packages>Demos & Packages</h2><ul><li><a href=https://github.com/ChicagoHAI/hypothesis-generation>Hypothesis generation</a></li><li><a href=https://delegability.github.io>Task delegability</a>, should AI be used for X?</li><li><a href=https://redditvisualization.herokuapp.com/>Reddit genealogy</a>, visualizing the genealogy between Reddit communities.</li></ul><p>If you want to learn more about my research, check my <a href=/papers>papers</a>. And kudos to all my <a href=/collaborators>collaborators</a>!</p><footer><hr>© Chenhao Tan 2025 (made with <a href=https://github.com/yihui/hugo-xmin/>Hugo XMin</a>) | <a href=https://github.com/ChicagoHAI/>Github</a> | <a href="https://scholar.google.com/citations?user=KGMaP18AAAAJ&amp;hl=en">Google Scholar</a> | <a href=https://bsky.app/profile/chenhaotan.bsky.social>Bluesky</a> | <a href=https://www.linkedin.com/in/chenhao-tan-2a446316/>LinkedIn</a></footer></body></html>