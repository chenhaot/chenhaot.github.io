<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>delegability | A minimal Hugo website</title>
<link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><script src=https://kit.fontawesome.com/cdd93c4598.js crossorigin=anonymous></script></head><body><nav><ul class=menu><li><a href=/>Home</a></li><li><a href=/papers/>Papers</a></li><li><a href=/talks/>Talks</a></li><li><a href=/courses/>Courses</a></li><li><a href=/contact/>Contact</a></li><li><a href=/blog/>Blog</a></li><li><a href=https://chicagohai.github.io/>Lab</a></li></ul><hr></nav><main><h2 id=ask-not-what-ai-can-do-but-what-ai-should-do-towards-a-framework-of-task-delegability>Ask Not What AI Can Do, But What AI Should Do: Towards a Framework of Task Delegability</h2><p><a href=http://blubars.github.io/pages/about.html>Brian Lubars</a> and Chenhao Tan.<br>In Proceedings of Thirty-third Conference on Neural Information Processing Systems (NeurIPS'2019) (spotlight presentation).</p><p><strong>Abstract:</strong><br>Although artificial intelligence holds promise for addressing societal challenges, issues of exactly which tasks to automate and the extent to do so remain understudied. We approach the problem of task delegability from a human-centered perspective by developing a framework on human perception of task delegation to artificial intelligence. We consider four high-level factors that can contribute to a delegation decision: motivation, difficulty, risk, and trust. To obtain an empirical understanding of human preferences in different tasks, we build a dataset of 100 tasks from academic papers, popular media portrayal of AI, and everyday life. For each task, we administer a survey to collect judgments of each factor and ask subjects to pick the extent to which they prefer AI involvement. We find little preference for full AI control and a strong preference for machine-in-the-loop designs, in which humans play the leading role. Our framework can effectively predict human preferences in degrees of AI assistance. Among the four factors, trust is the most predictive of human preferences of optimal human-machine delegation. This framework represents a first step towards characterizing human preferences of automation across tasks. We hope this work may encourage and aid in future efforts towards understanding such individual attitudes; our goal is to inform the public and the AI research community rather than dictating any direction in technology development.</p><p>[<a href=/pubs/delegation/delegation-ai.pdf>PDF</a>] [[Slides] <a href=/pubs/delegation/task-delegability-neurips-2019-slides.pdf>slides_link</a>] [<a href=/pubs/delegation/delegation-ai-supplementary.pdf>Supplementary</a>] [<a href=https://youtu.be/diaYtomuQ24>Video</a>] [<a href=http://delegability.github.io>Data & demo</a>]</p><p>@inproceedings{lubars+tan:19,<br>    
author = {Brian Lubars and Chenhao Tan},<br>    
title = {Ask Not What AI Can Do, But What AI Should Do: Towards a Framework of Task Delegability},<br>    
year = {2019},<br>    
booktitle = {Proceedings of NeurIPS}<br>}</p></main><footer><hr>© Chenhao Tan 2025 (made with <a href=https://github.com/yihui/hugo-xmin/>Hugo XMin</a>) | <a href=https://github.com/ChicagoHAI/>Github</a> | <a href="https://scholar.google.com/citations?user=KGMaP18AAAAJ&amp;hl=en">Google Scholar</a> | <a href=https://bsky.app/profile/chenhaotan.bsky.social>Bluesky</a> | <a href=https://www.linkedin.com/in/chenhao-tan-2a446316/>LinkedIn</a></footer></body></html>