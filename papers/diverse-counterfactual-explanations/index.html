<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>diverse counterfactual explanations | A minimal Hugo website</title><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><script src=https://kit.fontawesome.com/cdd93c4598.js crossorigin=anonymous></script></head><body><nav><ul class=menu><li><a href=/>Home</a></li><li><a href=/papers/>Papers</a></li><li><a href=/talks/>Talks</a></li><li><a href=/courses/>Courses</a></li><li><a href=/contact/>Contact</a></li><li><a href=https://substack.com/@cichicago>Blog</a></li><li><a href=https://chicagohai.github.io/>Lab</a></li></ul><hr></nav><main><h2 id=explaining-machine-learning-classifiers-through-diverse-counterfactual-explanations>Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations</h2><p>Ramaravind Kommiya Mothilal, <a href=http://www.amitsharma.in/>Amit Sharma</a> and Chenhao Tan.<br>In Proceedings of ACM FAT* Conference 2020.</p><p><strong>Abstract:</strong><br>Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at <a href=https://github.com/microsoft/DiCE>https://github.com/microsoft/DiCE</a>.</p><p>[<a href=https://arxiv.org/pdf/1905.07697.pdf>PDF</a>] [<a href=/pubs/counterfactuals/slides_conf.pdf>Slides</a>] [<a href=https://github.com/microsoft/DiCE>Code</a>]</p><p><img src=https://chenhaot.com/pubs/counterfactuals/example.png alt=tuotrial.></p><p>@inproceedings{mothilal+sharma+tan:20,<br>    
author = {Ramaravind K. Mothilal and Amit Sharma and Chenhao Tan},<br>    
title = {Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations},<br>    
year = {2020},<br>    
booktitle = {Proceedings of FAT*}<br>}</p></main><footer><hr>© Chenhao Tan 2025 (made with <a href=https://github.com/yihui/hugo-xmin/>Hugo XMin</a>) | <a href=https://github.com/ChicagoHAI/>Github</a> | <a href="https://scholar.google.com/citations?user=KGMaP18AAAAJ&amp;hl=en">Google Scholar</a> | <a href=https://bsky.app/profile/chenhaotan.bsky.social>Bluesky</a> | <a href=https://www.linkedin.com/in/chenhao-tan-2a446316/>LinkedIn</a></footer></body></html>