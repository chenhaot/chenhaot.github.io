<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>explanation few-shot NLP | Welcome to Chenhao Tan's Personal Website!</title><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><script src=https://kit.fontawesome.com/cdd93c4598.js crossorigin=anonymous></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-QD5VPF7ZFK"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-QD5VPF7ZFK")}</script><meta property="og:type" content="website"><meta property="og:url" content="https://chenhaot.github.io/papers/explanation-few-shot-nlp/"><meta property="og:title" content="explanation few-shot NLP | Welcome to Chenhao Tan's Personal Website!"><meta property="og:description" content="Investigating the Effect of Natural Language Explanations on Out-of-Distribution Generalization in Few-shot NLI
Yangqiaoyu Zhou and Chenhao Tan.         
In Workshop on Insights from Negative Results in NLP at EMNLP 2021.
Abstract:
Although neural models have shown strong performance in datasets such as SNLI, they lack the ability to generalize out-of-distribution (OOD). In this work, we formulate a few-shot learning setup and examine the effects of natural language explanations on OOD generalization. We leverage the templates in the HANS dataset and construct templated natural language explanations for each template. Although generated explanations show competitive BLEU scores against groundtruth explanations, they fail to improve prediction performance. We further show that generated explanations often hallucinate information and miss key elements that indicate the label."><meta property="og:image" content="https://chenhaot.github.io//images/web_circle_small.jpg"><meta property="twitter:card" content="summary"><meta property="twitter:url" content="https://chenhaot.github.io/papers/explanation-few-shot-nlp/"><meta property="twitter:title" content="explanation few-shot NLP | Welcome to Chenhao Tan's Personal Website!"><meta property="twitter:description" content="Investigating the Effect of Natural Language Explanations on Out-of-Distribution Generalization in Few-shot NLI
Yangqiaoyu Zhou and Chenhao Tan.         
In Workshop on Insights from Negative Results in NLP at EMNLP 2021.
Abstract:
Although neural models have shown strong performance in datasets such as SNLI, they lack the ability to generalize out-of-distribution (OOD). In this work, we formulate a few-shot learning setup and examine the effects of natural language explanations on OOD generalization. We leverage the templates in the HANS dataset and construct templated natural language explanations for each template. Although generated explanations show competitive BLEU scores against groundtruth explanations, they fail to improve prediction performance. We further show that generated explanations often hallucinate information and miss key elements that indicate the label."><meta property="twitter:image" content="https://chenhaot.github.io//images/web_circle_small.jpg"></head><body><nav><ul class=menu><li><a href=/>Home</a></li><li><a href=/papers/>Papers</a></li><li><a href=/talks/>Talks</a></li><li><a href=/courses/>Courses</a></li><li><a href=/contact/>Contact</a></li><li><a href=https://substack.com/@cichicago>Blog</a></li><li><a href=https://chicagohai.github.io/>Lab</a></li></ul><hr></nav><main><h2 id=investigating-the-effect-of-natural-language-explanations-on-out-of-distribution-generalization-in-few-shot-nli>Investigating the Effect of Natural Language Explanations on Out-of-Distribution Generalization in Few-shot NLI</h2><p><a href=https://rosafish.github.io>Yangqiaoyu Zhou</a> and <em>Chenhao Tan</em>.<br>In Workshop on Insights from Negative Results in NLP at EMNLP 2021.</p><p><strong>Abstract:</strong><br>Although neural models have shown strong performance in datasets such as SNLI, they lack the ability to generalize out-of-distribution (OOD). In this work, we formulate a few-shot learning setup and examine the effects of natural language explanations on OOD generalization. We leverage the templates in the HANS dataset and construct templated natural language explanations for each template. Although generated explanations show competitive BLEU scores against groundtruth explanations, they fail to improve prediction performance. We further show that generated explanations often hallucinate information and miss key elements that indicate the label.</p><p>[<a href=https://arxiv.org/pdf/2110.06223.pdf>PDF</a>]
[<a href=https://github.com/ChicagoHAI/hans-explanations>Dataset</a>]</p><p><img src=https://chenhaot.com/pubs/emnlp21ws.png alt="generated exaplanations."></p><p>@inproceedings{zhou+tan:21,<br>    
author = {Yangqiaoyu Zhou and Chenhao Tan},<br>    
title = {Investigating the Effect of Natural Language Explanations on Out-of-Distribution Generalization in Few-shot NLI},<br>    
year = {2021},<br>    
booktitle = {Proceedings of Workshop on Insights from Negative Results in NLP at EMNLP}<br>}</p></main><footer><hr><p>© Chenhao Tan 2025 (made with <a href=https://github.com/yihui/hugo-xmin/>Hugo XMin</a>)</p><p><a href=https://github.com/ChicagoHAI/>Github</a> | <a href="https://scholar.google.com/citations?user=KGMaP18AAAAJ&amp;hl=en">Google Scholar</a> | <a href=https://x.com/ChenhaoTan>X</a> | <a href=https://bsky.app/profile/chenhaotan.bsky.social>Bluesky</a> | <a href=https://www.linkedin.com/in/chenhao-tan-2a446316/>LinkedIn</a></p></footer></body></html>