<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>feature importance | A minimal Hugo website</title>
<link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/fonts.css><script src=https://kit.fontawesome.com/cdd93c4598.js crossorigin=anonymous></script></head><body><nav><ul class=menu><li><a href=/>Home</a></li><li><a href=/papers/>Papers</a></li><li><a href=/talks/>Talks</a></li><li><a href=/courses/>Courses</a></li><li><a href=/contact/>Contact</a></li><li><a href=/blog/>Blog</a></li><li><a href=https://chicagohai.github.io/>Lab</a></li></ul><hr></nav><main><h2 id=many-faces-of-feature-importance-comparing-built-in-and-post-hoc-feature-importance-in-text-classification>Many Faces of Feature Importance: Comparing Built-in and Post-hoc Feature Importance in Text Classification</h2><p><a href=https://vivlai.github.io/>Vivian Lai</a>, <a href=https://joncaizheng.com/>Jon Z. Cai</a>, and <em>Chenhao Tan</em>.<br>In Proceedings of 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing (EMNLP'2019)</p><p><strong>Abstract:</strong><br>Feature importance is commonly used to explain machine predictions. While feature importance can be derived from a machine learning model with a variety of methods, the consistency of feature importance via different methods remains understudied. In this work, we systematically compare feature importance from built-in mechanisms in a model such as attention values and post-hoc methods that approximate model behavior such as LIME. Using text classification as a testbed, we find that 1) no matter which method we use, important features from traditional models such as SVM and XGBoost are more similar with each other, than with deep learning models; 2) post-hoc methods tend to generate more similar important features for two models than built-in methods. We further demonstrate how such similarity varies across instances. Notably, important features do not always resemble each other better when two models agree on the predicted label than when they disagree.</p><p>[<a href=https://chenhaot.com/pubs/explanations/feature-importance.pdf>PDF</a>]
[<a href=https://github.com/BoulderDS/feature-importance>Code</a>]</p><p><img src=https://chenhaot.com/pubs/explanations/feature.png alt=poster.></p><p>@inproceedings{lai+cai+tan:19,<br>    
author = {Vivian Lai and Jon Z. Cai and Chenhao Tan},<br>    
title = {Many Faces of Feature Importance: Comparing Built-in and Post-hoc Feature Importance in Text Classification},<br>    
year = {2019},<br>    
booktitle = {Proceedings of EMNLP}<br>}</p></main><footer><hr>© Chenhao Tan 2025 (made with <a href=https://github.com/yihui/hugo-xmin/>Hugo XMin</a>) | <a href=https://github.com/ChicagoHAI/>Github</a> | <a href="https://scholar.google.com/citations?user=KGMaP18AAAAJ&amp;hl=en">Google Scholar</a> | <a href=https://bsky.app/profile/chenhaotan.bsky.social>Bluesky</a> | <a href=https://www.linkedin.com/in/chenhao-tan-2a446316/>LinkedIn</a></footer></body></html>